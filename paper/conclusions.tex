\section{Conclusions}\label{sec:conclusion}

In this work, we apply a machine-learning algorithm that involves a Gaussian process as an interpolator to augment a stellar grid. We train GP models to convert a sparse model grid into continuous functions, which map five fundamental inputs to observable quantities. We find good precision and accuracy in GP-based interpolations when testing them with off-grid models. A GP-predicted model dataset is then generated and we use it to model 1,000 fake stars. Comparing with the original sparse grid, GP-predicted models have complete sampling across the parameter space and hence improve the accuracy and the precision of estimates, particularly for the stellar age.

The application of GP's make it efficient to generate a statistically-sound model dataset based on a sparse model grid. It works well for high-demission case (up to 5D in this work) and this can be a big advantage compared with traditional interpolators. The choice of kernel is crucial for the success of a particular case. We hence do a number of preliminary studies for the best option. A limitation of the training step for the GP is the size of the training data set and the requirement to perform matrix inversion and calculate the matrix determinant. For training a normal GP model, the practical training data size upper limit is around 20,000 (the number depends on the capacity of GPU device) which is apparently not big enough for the high-demission grid including $\sim$10,000,000 models. To overcome this issue, we section the training data according to their evolutionary stage ({\it EEP}) and train GP models for each section. This section scenario significantly improves overall accuracy of GP predictions and we find no edge effects at the boundary of sections. When inspecting the systematic uncertainty of GP models, we notice that GP predictions are very over-confident in the high-demission problem: the uncertainties given by GP models are mostly smaller than testing errors by an order of magnitude. Because of this,  we use the testing errors to estimate systematic uncertainties across the parameter space. Eventually, we provide a GP-based model dataset including 5,000,000 models with randomly sampled fundamental inputs.

We use GP-based models to characterise 1,000 fake stars to examine whether truths of stellar properties can be recovered. We find that GP-based masses and ages are consistent with the injected truth values. The uncertainties are dominated by observational noise, saying that, the systematic uncertainty due to the GP approximation does not obviously affect the modelling on interferences. Comparing with the probability distributions of original sparse grid, GP models are fully sampled in the input range and hence improve the accuracy and precision of inferred parameters. The improvement is remarkable for the stellar age (by 7\%). Moreover, the continuous sampling makes it possible to properly estimate some fundamental parameters which are sparse in the grid, e.g., the helium fraction. These results indicate that the method demonstrated in this work is reliable and efficient for interpolating an established model grid and it can improve the modelling solutions because of the statistically-sound sampling. 